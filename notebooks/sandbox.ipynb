{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENVIRONMENT\n",
    "\n",
    "from aisurveywriter.core.llm_handler import LLMHandler\n",
    "import aisurveywriter.core.file_handler as fh\n",
    "from aisurveywriter.utils import get_all_files_from_paths\n",
    "from aisurveywriter.core.pipeline import PaperPipeline\n",
    "from aisurveywriter.core.paper import PaperData\n",
    "import aisurveywriter.tasks as tks\n",
    "\n",
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"]=fh.read_credentials(\"../credentials.yaml\")[\"google_key\"]\n",
    "\n",
    "# llm = LLMHandler(model=\"qwen2.5:14b\", model_type=\"ollama\", temperature=0.5)\n",
    "prompts = fh.read_yaml(\"../templates/prompt_config.yaml\")\n",
    "review = fh.read_yaml(\"../templates/review_config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize default prompt store\n",
    "\n",
    "from aisurveywriter.store.prompt_store import PromptStore, default_prompt_store\n",
    "import json\n",
    "\n",
    "old = default_prompt_store()\n",
    "\n",
    "with open(\"prompts-20250320.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(old.model_dump(), f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual RAG retrieval\n",
    "\n",
    "from aisurveywriter.core.agent_rags import AgentRAG, RAGType\n",
    "from aisurveywriter.core.text_embedding import EmbeddingsHandler\n",
    "\n",
    "embed = EmbeddingsHandler(\"Snowflake/snowflake-arctic-embed-l-v2.0\", \"huggingface\")\n",
    "rag = AgentRAG(embed, bib_faiss_path=\"../out/refextract-bibdb.faiss\", \n",
    "               figures_faiss_path=\"../out/figures-rag.faiss\", \n",
    "               content_faiss_path=\"../out/content-rag.faiss\",\n",
    "               request_cooldown_sec=6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = r\"meniscus effect\"\n",
    "rag.retrieve(RAGType.ImageData, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aisurveywriter.core.text_embedding import EmbeddingsHandler\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embed = EmbeddingsHandler(\"Snowflake/snowflake-arctic-embed-l-v2.0\", \"huggingface\")\n",
    "faiss = FAISS.load_local(\"../out/refextract-bibdb.faiss\", embeddings=embed.model, allow_dangerous_deserialization=True)\n",
    "faiss.similarity_search_with_score(\"This review presents a comprehensive overview of these techniques, crucial for producing high-quality LB films. Ultimately, a deeper understanding of Langmuir monolayer characterization empowers the development of advanced materials and devices across diverse fields, pushing the boundaries of nanoscience and nanotechnology\", k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image caption extraction test\n",
    "from aisurveywriter.core.pdf_processor import PDFProcessor, LayoutParserSettings\n",
    "from aisurveywriter.utils.helpers import get_all_files_from_paths\n",
    "\n",
    "lp_settings = LayoutParserSettings(config_path=\"lp://PubLayNet/mask_rcnn_X_101_32x8d_FPN_3x/config\", tesseract_executable=\"/home/juliocesar/bin/tesseract\", score_threshold=0.7)\n",
    "\n",
    "pdf = PDFProcessor([\"../refexamples/all21/OliveiraO2022_PastAndFuture.pdf\"], lp_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aisurveywriter.store.reference_store import ReferenceStore\n",
    "import os\n",
    "\n",
    "refstore = ReferenceStore.from_local(\"../results/138refs-compatrycja/refstore.pkl\")\n",
    "for i, doc in enumerate(refstore.documents):\n",
    "    title = doc.title.replace(\"\\n\", \" \").strip() if doc.title else \"unk title\"\n",
    "    author = doc.author.replace(\"\\n\", \" \").strip() if doc.author else \"unk author\"\n",
    "    if author:\n",
    "        authors = author.split(\"*\") if \"*\" in author else author.split(\"and\")\n",
    "        if len(authors) > 2:\n",
    "            author = authors[0].strip() + \", et al.\"\n",
    "    name = os.path.basename(doc.path)\n",
    "    \n",
    "    if doc.bibtex_entry and \"doi\" in doc.bibtex_entry:\n",
    "        doi = \"https://doi.org/\" + doc.bibtex_entry[\"doi\"]\n",
    "    elif \"link\" in doc.bibtex_entry:\n",
    "        doi = doc.bibtex_entry[\"link\"]\n",
    "    elif \"url\" in doc.bibtex_entry:\n",
    "        doi = doc.bibtex_entry[\"doi\"]\n",
    "        \n",
    "    print(f\"{i+1}. {author}; \\\"{title}\\\" | {name} | {doi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from aisurveywriter.utils.helpers import get_all_files_from_paths, get_bibtex_entry\n",
    "import os\n",
    "import re\n",
    "\n",
    "title_pattern = re.compile(r\"^(?:title)\\s*[:\\.-]*\\s*(.+?)[\\n]\", re.IGNORECASE)\n",
    "\n",
    "refs = []\n",
    "paths = get_all_files_from_paths(\"../refexamples/rafael_and_lesscited_and_21/\", skip_ext=[\".pdf\"], stem_sort=True)\n",
    "for path in paths:\n",
    "    print(path)\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    base = os.path.basename(path)\n",
    "    print(base)\n",
    "    if title_match := title_pattern.search(content):\n",
    "        title = title_match.group(1).strip()\n",
    "        print(\"title match:\", title)\n",
    "        bib = get_bibtex_entry(title, None)\n",
    "        if not bib:\n",
    "            print(\"no bib found\\n\")\n",
    "            continue\n",
    "        \n",
    "        if bib and \"doi\" in bib:\n",
    "            doi = \"https://doi.org/\" + bib[\"doi\"]\n",
    "        elif \"link\" in bib:\n",
    "            doi = bib[\"link\"]\n",
    "        elif \"url\" in bib:\n",
    "            doi = bib[\"doi\"]\n",
    "        \n",
    "        refs.append((bib.get(\"author\", None), title, doi, base))\n",
    "\n",
    "\n",
    "for i, (author, title, doi, file) in enumerate(refs):\n",
    "    author = author.replace(\"\\n\", \" \").strip() if author else \"unk author\"\n",
    "    if author != \"unk author\":\n",
    "        authors = author.split(\"*\") if \"*\" in author else author.split(\"and\")\n",
    "        if len(authors) > 2:\n",
    "            author = authors[0].strip() + \", et al.\"\n",
    "\n",
    "    print(f\"{108+i}. {author}; \\\"{title}\\\" | {file} | {doi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_bibtex_entry(\"External Infrared Reflection Absorption Spectrometry of Monolayer Films at the Air-Water Interface\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from aisurveywriter.utils.helpers import get_bibtex_entry\n",
    "\n",
    "ref_pattern = re.compile(r\"(\\d+)\\.\\s(.+?);\\s\\\"(.+?)\\\"\\s\\|\\s(.+?)\\s\\|\\s(.+?)\\s*\\n\")\n",
    "\n",
    "ref_text = \"\"\n",
    "\n",
    "refs = []\n",
    "for match in ref_pattern.finditer(ref_text):\n",
    "    num = int(match.group(1).strip())\n",
    "    author = match.group(2).strip()\n",
    "    title = match.group(3).strip()\n",
    "    file = match.group(4).strip()\n",
    "    doi = match.group(5).strip()\n",
    "    \n",
    "    refs.append((num, author, title, file, doi))\n",
    "    \n",
    "for num, author, title, file, doi in refs[1:]:\n",
    "    print(f\"{num-1}. {author}; \\\"{title}\\\" | {doi} | {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with open(\"../results/review_references.txt\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "    \n",
    "    \n",
    "\n",
    "blocks = content.split(\"\\n\\n\")\n",
    "blocks = [block.strip() for block in blocks if block.strip()]\n",
    "versions = {}\n",
    "ref_pattern = re.compile(r\"(\\d+)\\.\\s(.+?);\\s\\\"(.+?)\\\"\\s\\|\\s(.+?)\\s\\|\\s(.+?)\\.(pdf|txt)\")\n",
    "version_pattern = re.compile(r\"Version:\\s\\\"(.+?)\\\"\")\n",
    "for block in blocks:\n",
    "    version = version_pattern.match(block).group(1).strip()\n",
    "    refs = []\n",
    "    for match in ref_pattern.finditer(block):\n",
    "        num = int(match.group(1).strip())\n",
    "        author = match.group(2).strip()\n",
    "        title = match.group(3).strip()\n",
    "        doi = match.group(4).strip()\n",
    "        file = match.group(5).strip() + \".\" + match.group(6).strip()\n",
    "        refs.append((num, author, title, doi, file))\n",
    "    versions[version] = refs\n",
    "\n",
    "def generate_markdown_references(versions_dict):\n",
    "    from textwrap import dedent\n",
    "\n",
    "    # Flatten all items to calculate max width for each field\n",
    "    all_refs = [ref for refs in versions_dict.values() for ref in refs]\n",
    "    max_author_len = max(len(ref[1]) for ref in all_refs)\n",
    "    max_title_len = max(len(ref[2]) for ref in all_refs)\n",
    "    max_doi_len = max(len(ref[3]) for ref in all_refs)\n",
    "\n",
    "    def format_ref(ref):\n",
    "        num, author, title, doi, _ = ref\n",
    "        return (\n",
    "            f\"{str(num)}. \"\n",
    "            f\"{author.ljust(max_author_len)} | \"\n",
    "            f\"{title.ljust(max_title_len)} | \"\n",
    "            f\"{doi.ljust(max_doi_len)}\"\n",
    "        )\n",
    "\n",
    "    markdown_lines = []\n",
    "    for version, refs in versions_dict.items():\n",
    "        markdown_lines.append(f\"### {version}\\n\")\n",
    "        for ref in refs:\n",
    "            markdown_lines.append(f\"{format_ref(ref)}\")\n",
    "        markdown_lines.append(\"\")  # Extra newline after each version\n",
    "\n",
    "    return \"\\n\".join(markdown_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_refs = versions[\"138refs-compatrycja\"]\n",
    "all_refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bibtexparser\n",
    "from aisurveywriter.utils.helpers import get_bibtex_entry\n",
    "\n",
    "all_refs = versions[\"138refs-compatrycja\"]\n",
    "db = bibtexparser.bibdatabase.BibDatabase()\n",
    "\n",
    "for num, author, title, doi, file in all_refs:\n",
    "    if \"et al.\" in author:\n",
    "        author = author[:author.find(\"et al.\")].strip()\n",
    "    bib = get_bibtex_entry(title, author)\n",
    "    if not bib:\n",
    "        bib = get_bibtex_entry(title, None)\n",
    "    print(bib)\n",
    "    db.entries.append(bib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "backup = copy.deepcopy(db.entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "for entry, (num, author, title, doi, file) in zip(db.entries, all_refs):\n",
    "    entry = copy.deepcopy(entry)\n",
    "    if \"doi\" in entry:\n",
    "        entry_doi = \"https://doi.org/\" + entry[\"doi\"]\n",
    "    elif \"link\" in entry:\n",
    "        entry_doi = entry[\"link\"]\n",
    "    elif \"url\" in entry:\n",
    "        entry_doi = entry[\"url\"]\n",
    "    else:\n",
    "        print(\"unable to find doi in entry:\", entry, file)\n",
    "        print()\n",
    "        entry_doi = None\n",
    "    \n",
    "    if entry_doi and doi != entry_doi:\n",
    "        print(\"doi doesnt match:\", doi, entry_doi, file, num)\n",
    "        print(entry[\"ID\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = bibtexparser.loads(\"\"\"@article{Palto1996,\n",
    "author = {S. Palto and L. Blinov and A. Bune and E. Dubovik and V. Fridkin and N. Petukhova and K. Verkhovskaya and S. Yudin and},\n",
    "title = {Ferroelectric langmuir-blodgett films},\n",
    "journal = {Ferroelectrics},\n",
    "volume = {184},\n",
    "number = {1},\n",
    "pages = {127--129},\n",
    "year = {1996},\n",
    "publisher = {Taylor \\& Francis},\n",
    "doi = {10.1080/00150199608230252},\n",
    "URL = {https://doi.org/10.1080/00150199608230252},\n",
    "eprint = {https://doi.org/10.1080/00150199608230252},\n",
    "abstract = {Ferroelectric Langmuir-Blodgett films are prepared and investigated for the first time. The films are prepared from the ferroelectric copolymer of vinylidene fluoride with trifluorethylene. Films with a thickness of 150Ã… show a pyroelectric effect, remnant polarization switching and a ferroelectric phase transition of the first order, characterized by temperature hysteresis. }\n",
    "}\"\"\").entries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(db.entries[1])\n",
    "all_refs = [list(ref) for ref in all_refs]\n",
    "for entry, ref in zip(db.entries, all_refs):\n",
    "    if \"doi\" in entry:\n",
    "        doi = \"https://doi.org/\" + entry[\"doi\"]\n",
    "    elif \"link\" in entry:\n",
    "        doi = entry[\"link\"]\n",
    "    elif \"url\" in entry:\n",
    "        doi = entry[\"url\"]\n",
    "    else:\n",
    "        continue\n",
    "    ref[-2] = doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_refs[136]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"refs.bib\", \"w\", encoding=\"utf-8\") as f:\n",
    "    bibtexparser.dump(db, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"refs.bib\", \"r\", encoding=\"utf-8\") as f:\n",
    "    db = bibtexparser.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tex = \"\"\n",
    "for version in versions:\n",
    "    tex = f\"\"\"\\\\section{{{version}}}\n",
    "    \\\\begin{{enumerate}}\n",
    "\"\"\"\n",
    "    version_refs = versions[version]\n",
    "    ref_text = \"\"\n",
    "    for i, (num, author, title, doi, file) in enumerate(version_refs):\n",
    "        updated_ref = [ref for ref in all_refs if ref[-1] == file][0]\n",
    "        version_refs[i] = updated_ref.copy()\n",
    "        version_refs[i][0] = num\n",
    "    \n",
    "    for i, (num, author, title, doi, file) in enumerate(version_refs):\n",
    "        ref_entry = None\n",
    "        for entry in db.entries:\n",
    "            if \"doi\" in entry:\n",
    "                if entry[\"doi\"] in doi:\n",
    "                    ref_entry = entry\n",
    "                    break\n",
    "            if \"link\" in entry:\n",
    "                if entry[\"link\"] == doi:\n",
    "                    ref_entry = entry\n",
    "                    break\n",
    "            if \"url\" in entry:\n",
    "                if entry[\"url\"] == doi:\n",
    "                    ref_entry = entry\n",
    "            if entry[\"title\"].lower().strip() == title.lower().strip():\n",
    "                ref_entry = entry\n",
    "        \n",
    "        ref_text += f\"        \\\\item {author}, {ref_entry.get(\"year\", None)} \\\\cite{{{ref_entry[\"ID\"]}}}\\n\"\n",
    "    \n",
    "    tex += ref_text + \"   \\\\end{enumerate}\"\n",
    "    all_tex += tex + \"\\n\\n\"\n",
    "\n",
    "print(all_tex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
