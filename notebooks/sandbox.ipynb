{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====> ENVIRONMENT SETUP\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "def read_yaml(fpath: str) -> dict:\n",
    "    with open(fpath, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    return data\n",
    "\n",
    "APIKEYS = read_yaml(\"../apikeys.yaml\")\n",
    "os.environ[\"GOOGLE_API_KEY\"]=APIKEYS[\"google\"]\n",
    "os.environ[\"OPENAI_API_KEY\"]=APIKEYS[\"openai\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "llm.invoke([HumanMessage(content=\"Write a poem about the moon\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeling testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pdf data from references\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_files = [\n",
    "    \"../refexamples/ArigaK2023_Langmuir.pdf\",\n",
    "    \"../refexamples/FangC_ApplicationsLangmuir.pdf\",\n",
    "]\n",
    "doc_data = []\n",
    "for file in pdf_files:\n",
    "    loader = PyPDFLoader(file)\n",
    "    doc_data.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "with open(\"../paper_instructions.yaml\", \"r\") as f:\n",
    "    paper = yaml.safe_load(f)\n",
    "\n",
    "pdf_data = \"\\n\".join([doc.page_content for doc in doc_data])\n",
    "prompt_fmt = paper[\"base_prompt_format\"] + \"\\n\\nThe accompanying PDF data for the references is:\\n{pdf_data}\"\n",
    "prep_instructions = paper[\"preparation_instructions\"]\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"preparation_instructions\", \"title\", \"subject\", \"description\"],\n",
    "    template=paper[\"base_prompt_format\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "gen_sections = []\n",
    "\n",
    "for section in paper[\"sections\"]:\n",
    "    response = chain.run({\n",
    "        \"preparation_instructions\": prep_instructions,\n",
    "        \"subject\": paper[\"subject\"],\n",
    "        \"pdf_data\": pdf_data,\n",
    "        \"title\": section[\"title\"],\n",
    "        \"description\": section[\"description\"],\n",
    "    })\n",
    "    gen_sections.append({\"title\": section[\"title\"], \"content\": response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gen_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = {\"sections\": gen_sections}\n",
    "with open(\"generated20241213\", \"w\") as f:\n",
    "    yaml.dump(dump, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protoyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Input to ChatPromptTemplate is missing variables {'title', 'description', 'subject'}.  Expected: ['description', 'subject', 'title'] Received: ['Langmuir Monolayers and Langmuir-Blodgett Films', 'Introduction', '-Definition and Importance\\\\n  -Definition of Langmuir monolayers and LB films.\\\\n  -Highlight the importance of these films in nanoscience and nanotechnology.\\\\n  -Brief mention of applications in areas such as electronics, sensors, biomedicine, etc.\\\\n-Comparison with Similar Films\\\\n  -Compare and contrast LB films with other thin-film techniques, such as self-assembled monolayers (SAMs) and layer-by-layer (LbL) films.\\\\n  -Discussion of the advantages and disadvantages of each technique in relation to molecular precision, scalability, and versatility.\\\\n  -llustration (Figure): Schematic comparison of LB, SAM, and LbL techniques. (Original artwork)\\\\n']\\nNote: if you intended {title} to be part of the string and not a variable, please escape it with double curly braces like: '{{title}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 155\u001b[0m\n\u001b[1;32m    148\u001b[0m     dump_generated_sections({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msections\u001b[39m\u001b[38;5;124m\"\u001b[39m: paper_content}, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout/lastgeneration.dump\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    149\u001b[0m     save_latex_sections(\n\u001b[1;32m    150\u001b[0m         tex_template_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../templates/paper_template.tex\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    151\u001b[0m         sections\u001b[38;5;241m=\u001b[39mpaper_content,\n\u001b[1;32m    152\u001b[0m         outpath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout/lastgenerated.tex\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 155\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 138\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m paper_content \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m section \u001b[38;5;129;01min\u001b[39;00m paper_structure[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msections\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    135\u001b[0m     paper_content\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    136\u001b[0m         {\n\u001b[1;32m    137\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: section[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m--> 138\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mwrite_section\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaper_subject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msection\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msection\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdescription\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    139\u001b[0m         }\n\u001b[1;32m    140\u001b[0m     )\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mprint\u001b[39m(paper_content)\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m====> FINISHED WRITING SECTION:\u001b[39m\u001b[38;5;124m\"\u001b[39m, section[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[5], line 59\u001b[0m, in \u001b[0;36mwrite_section\u001b[0;34m(chain, subject, title, description)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_section\u001b[39m(chain: ConversationChain, subject: \u001b[38;5;28mstr\u001b[39m, title: \u001b[38;5;28mstr\u001b[39m, description: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Write the given section \"\"\"\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubject\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msubject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_core/runnables/base.py:3022\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m   3021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 3022\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3023\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3024\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_core/prompts/base.py:208\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[1;32m    207\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserialized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serialized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_core/runnables/base.py:1927\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1923\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1924\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1925\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1926\u001b[0m         Output,\n\u001b[0;32m-> 1927\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1928\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1929\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1930\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1931\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1932\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1935\u001b[0m     )\n\u001b[1;32m   1936\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1937\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_core/runnables/config.py:396\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    395\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_core/prompts/base.py:182\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[0;32m--> 182\u001b[0m     _inner_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_prompt(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_inner_input)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_core/prompts/base.py:176\u001b[0m, in \u001b[0;36mBasePromptTemplate._validate_input\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    170\u001b[0m     example_key \u001b[38;5;241m=\u001b[39m missing\u001b[38;5;241m.\u001b[39mpop()\n\u001b[1;32m    171\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNote: if you intended \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m to be part of the string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and not a variable, please escape it with double curly braces like: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m     )\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m    177\u001b[0m         create_message(message\u001b[38;5;241m=\u001b[39mmsg, error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mINVALID_PROMPT_INPUT)\n\u001b[1;32m    178\u001b[0m     )\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inner_input\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Input to ChatPromptTemplate is missing variables {'title', 'description', 'subject'}.  Expected: ['description', 'subject', 'title'] Received: ['Langmuir Monolayers and Langmuir-Blodgett Films', 'Introduction', '-Definition and Importance\\\\n  -Definition of Langmuir monolayers and LB films.\\\\n  -Highlight the importance of these films in nanoscience and nanotechnology.\\\\n  -Brief mention of applications in areas such as electronics, sensors, biomedicine, etc.\\\\n-Comparison with Similar Films\\\\n  -Compare and contrast LB films with other thin-film techniques, such as self-assembled monolayers (SAMs) and layer-by-layer (LbL) films.\\\\n  -Discussion of the advantages and disadvantages of each technique in relation to molecular precision, scalability, and versatility.\\\\n  -llustration (Figure): Schematic comparison of LB, SAM, and LbL techniques. (Original artwork)\\\\n']\\nNote: if you intended {title} to be part of the string and not a variable, please escape it with double curly braces like: '{{title}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \""
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain import PromptTemplate, ConversationChain, LLMChain\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.prompts.chat import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import re\n",
    "import os\n",
    "from time import sleep\n",
    "\n",
    "def get_pdf_contents(pdf_paths: List[str]):\n",
    "    doc_data = []\n",
    "    for file in pdf_paths:\n",
    "        loader = PyPDFLoader(file)\n",
    "        doc_data.extend(loader.load())\n",
    "    return doc_data\n",
    "\n",
    "def generate_paper_structure(prompt: str, subject: str, pdf_paths: List[str]):\n",
    "    \"\"\" Generate paper structure using NotebookLM \"\"\"\n",
    "    if prompt.find(\"{subject}\") != -1:\n",
    "        prompt = prompt.replace(\"{subject}\", subject)\n",
    "\n",
    "    # Use NotebookLM bot to send it\n",
    "    \n",
    "    # Save structure to \"templates/paper_structure.yaml\"\n",
    "    pass\n",
    "\n",
    "def setup_context_msg(preparation_yaml_path: str, pdf_paths: List[str]):\n",
    "    \"\"\" Setup context SystemMessage with writing instructions + PDFs contents \"\"\"\n",
    "    preparation = read_yaml(preparation_yaml_path)\n",
    "    \n",
    "    context = f\"For this context, be aware:\"\n",
    "    for prep in preparation:\n",
    "        context += f\"\\n{preparation[prep]}\"\n",
    "    \n",
    "    pdf_content = get_pdf_contents(pdf_paths)\n",
    "    context += \"\\n\\nThe PDF content of the given references are:\\n\"\n",
    "    context += \"\\n\".join([doc.page_content for doc in pdf_content])\n",
    "\n",
    "    return SystemMessage(content=context)\n",
    "\n",
    "def init_chain(llm, ctx_msg: SystemMessage, write_prompt_yaml: str) -> ConversationChain:\n",
    "    \"\"\" Setup LLMChain with proper prompts and context \"\"\"\n",
    "    prompt_fmt = read_yaml(write_prompt_yaml)\n",
    "\n",
    "    req_prompt = HumanMessagePromptTemplate.from_template(prompt_fmt[\"base_prompt_format\"])\n",
    "    \n",
    "    full_prompt = ChatPromptTemplate.from_messages([ctx_msg, req_prompt])\n",
    "    # chain = LLMChain(\n",
    "    #     llm=llm,\n",
    "    #     prompt=full_prompt\n",
    "    # )\n",
    "    chain = full_prompt | llm\n",
    "    return full_prompt, chain\n",
    "\n",
    "def write_section(chain: ConversationChain, subject: str, title: str, description: str) -> str:\n",
    "    \"\"\" Write the given section \"\"\"\n",
    "    return chain.invoke({\n",
    "        \"subject\": subject,\n",
    "        \"title\": title,\n",
    "        \"description\": description,\n",
    "    })\n",
    "\n",
    "def dump_generated_sections(sections: dict, outpath: str):\n",
    "    with open(outpath, \"w\", encoding=\"utf-8\") as f:\n",
    "        yaml.safe_dump(sections, f)\n",
    "\n",
    "\n",
    "def save_latex_sections(tex_template_path: str, sections: List[dict], outpath: str):\n",
    "    \"\"\" \n",
    "    Join the contents of every section to the output LaTeX file \n",
    "    'sections' must be a list of dictionaries with two keys: 'title' and 'content'\n",
    "    \"\"\"\n",
    "\n",
    "    with open(tex_template_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        tex_template = f.read()\n",
    "\n",
    "    paper_content = \"\"\n",
    "    \n",
    "    bib_content = \"\"\n",
    "    bib_pattern = r\"\\\\begin{filecontents\\*}(.*?)\\\\end{filecontents\\*}\"\n",
    "\n",
    "    for section in sections:\n",
    "        # Extract biblatex file content\n",
    "        match = re.search(bib_pattern, section[\"content\"], re.DOTALL)\n",
    "        sec_bib_content = match.group(1).strip() if match else None\n",
    "        if sec_bib_content is None:\n",
    "            print(\"FAILED TO MATCH BIBLATEX CONTENT IN SECTION:\", section[\"title\"])\n",
    "            continue\n",
    "\n",
    "        section_text = re.sub(bib_pattern, \"\", section[\"content\"], flags=re.DOTALL)\n",
    "        \n",
    "        paper_content += section_text\n",
    "        bib_content += sec_bib_content\n",
    "    bib_content = bib_content.replace(\"{mybib.bib}\", \"\")\n",
    "    bib_file = outpath+\"bib.bib\"\n",
    "    \n",
    "    # Replace paper content in latex template and save it\n",
    "    tex_content = tex_template.replace(\"{content}\", paper_content).replace(\"{bibresourcefile}\", os.path.basename(bib_file))\n",
    "    with open(outpath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(tex_content)\n",
    "\n",
    "    # also save the biblatex file\n",
    "    with open(bib_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(bib_content)\n",
    "\n",
    "\n",
    "def main():\n",
    "    pdf_paths = [\n",
    "        \"../refexamples/ArigaK2023_Langmuir.pdf\",\n",
    "        \"../refexamples/FangC_ApplicationsLangmuir.pdf\",\n",
    "        \"../refexamples/ArigaK2022_PastAndFutureLangmuir.pdf\",\n",
    "        # \"../refexamples/LuC2024_AIScientist.pdf\"\n",
    "    ]\n",
    "    struct_generation = read_yaml(\"../templates/gen_paper_structure.yaml\")\n",
    "    paper_subject = struct_generation[\"subject\"]\n",
    "    # paper_structure = generate_paper_structure(\n",
    "    #     prompt=struct_generation[\"gen_struct_prompt\"],\n",
    "    #     subject=paper_subject,\n",
    "    #     pdf_paths=pdf_paths,\n",
    "    # )\n",
    "\n",
    "    ctx = setup_context_msg(\n",
    "        preparation_yaml_path=\"../templates/preparation.yaml\",\n",
    "        pdf_paths=pdf_paths,\n",
    "    )\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
    "    prompt, chain = init_chain(llm, ctx, \"../templates/write_prompt_fmt.yaml\")\n",
    "    # print(prompt.format_prompt(title=\"Ola\",subject=\"Tchau\",description=\"dadsf\").to_string())\n",
    "\n",
    "    paper_structure = read_yaml(\"../templates/paper_structure.yaml\")\n",
    "    paper_content = []\n",
    "    for section in paper_structure[\"sections\"]:\n",
    "        paper_content.append(\n",
    "            {\n",
    "                \"title\": section[\"title\"],\n",
    "                \"content\": write_section(chain, paper_subject, section[\"title\"], section[\"description\"]),\n",
    "            }\n",
    "        )\n",
    "        print(paper_content)\n",
    "        print(\"====> FINISHED WRITING SECTION:\", section[\"title\"])\n",
    "        break\n",
    "        # wait because of gemini-1.5-pro quota (2 RPM, 32000 TPM)\n",
    "        sleep(60*1.4)\n",
    "\n",
    "    os.makedirs(\"out\", exist_ok=True)\n",
    "    dump_generated_sections({\"sections\": paper_content}, \"out/lastgeneration.dump\")\n",
    "    save_latex_sections(\n",
    "        tex_template_path=\"../templates/paper_template.tex\",\n",
    "        sections=paper_content,\n",
    "        outpath=\"out/lastgenerated.tex\",\n",
    "    )\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
