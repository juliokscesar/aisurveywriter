{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio interface prototype\n",
    "from typing import List\n",
    "import gradio as gr\n",
    "#from aisurveywriter import generate_paper_survey\n",
    "\n",
    "def generate_paper_survey(msg, paths, sp):\n",
    "    print(f\"INSIDE GEN PAPER SURVEY: {msg}, {paths}, {sp}\")\n",
    "    return \"TESTING\"\n",
    "\n",
    "def chat_fn(message, history, refs, save_path):\n",
    "    print(f\"DEBUG: message={message}, HISTORY={history}, REFS={refs}, PDF_PATHS={save_path}\")\n",
    "    pdf_paths = [file.name for file in refs]\n",
    "    result = generate_paper_survey(message, pdf_paths, save_path)\n",
    "    return \"The genereated papar content is: \" + result\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=chat_fn,\n",
    "    textbox=gr.Textbox(placeholder=\"Enter the subject of the survey paper...\"),\n",
    "    additional_inputs=[\n",
    "        gr.File(label=\"Upload reference PDFs\", file_types=[\".pdf\"], file_count=\"multiple\"),\n",
    "        gr.Textbox(label=\"Save path and name\", placeholder=\"Enter the full path to save the paper (including its filename)\"),\n",
    "    ],\n",
    "    title=\"Survey Paper Writer\",\n",
    "    description=\"Provide a subject, reference PDFs, and a save path to generate and save a survey paper.\",\n",
    ")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bibtex from (title and author) or DOI\n",
    "\n",
    "import requests\n",
    "import bibtexparser\n",
    "from bibtexparser.bparser import BibTexParser\n",
    "from bibtexparser.bibdatabase import BibDatabase\n",
    "\n",
    "def search_crossref(title, author):\n",
    "    \"\"\"\n",
    "    Search CrossRef API using title and author to retrieve the DOI.\n",
    "    \"\"\"\n",
    "    url = \"https://api.crossref.org/works\"\n",
    "    params = {\"query.title\": title, \"query.author\": author, \"rows\": 1}\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        items = data.get(\"message\", {}).get(\"items\", [])\n",
    "        if items:\n",
    "            return items[0].get(\"DOI\")\n",
    "    return None\n",
    "\n",
    "def get_bibtext(doi, cache={}):\n",
    "    \"\"\"\n",
    "    Use DOI Content Negotiation to retrieve a string with the bibtex entry.\n",
    "    \"\"\"\n",
    "    if doi in cache:\n",
    "        return cache[doi]\n",
    "    url = f'https://doi.org/{doi}'\n",
    "    headers = {'Accept': 'application/x-bibtex'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        bibtext = response.text\n",
    "        cache[doi] = bibtext\n",
    "        return bibtext\n",
    "    return None\n",
    "\n",
    "def get_abstract(doi):\n",
    "    \"\"\"\n",
    "    Retrieve the abstract of a paper using the CrossRef API.\n",
    "    \"\"\"\n",
    "    url = f'https://api.crossref.org/works/{doi}'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(data.get(\"message\",{}))\n",
    "        return data.get('message', {}).get('abstract', None)\n",
    "    return None\n",
    "\n",
    "def get_bibtex_entry(title, author, bibtext_cache={}):\n",
    "    \"\"\"\n",
    "    Retrieve BibTeX entry using title and author.\n",
    "    \"\"\"\n",
    "    doi = search_crossref(title, author)\n",
    "    if not doi:\n",
    "        print(\"DOI not found for given title and author.\")\n",
    "        return None\n",
    "    \n",
    "    bibtext = get_bibtext(doi, cache=bibtext_cache)\n",
    "    if not bibtext:\n",
    "        print(\"BibTeX entry not found.\")\n",
    "        return None\n",
    "    \n",
    "    parser = BibTexParser()\n",
    "    parser.ignore_nonstandard_types = False\n",
    "    bibdb = bibtexparser.loads(bibtext, parser)\n",
    "    entry, = bibdb.entries\n",
    "    entry['link'] = f'https://doi.org/{doi}'\n",
    "    \n",
    "    if 'author' in entry:\n",
    "        entry['author'] = ' and '.join(entry['author'].rstrip(';').split('; '))\n",
    "    \n",
    "    entry['ID'] = doi.split('/')[-1]\n",
    "    \n",
    "    # Retrieve and add abstract\n",
    "    abstract = get_abstract(doi)\n",
    "    if abstract:\n",
    "        entry['abstract'] = abstract\n",
    "    \n",
    "    return entry\n",
    "\n",
    "def entries_to_str(entries):\n",
    "    \"\"\"\n",
    "    Pass a list of bibtexparser entries and return a bibtex formatted string.\n",
    "    \"\"\"\n",
    "    db = BibDatabase()\n",
    "    db.entries = entries\n",
    "    return bibtexparser.dumps(db)\n",
    "\n",
    "# Example usage\n",
    "title = \"Chemistry of Materials Nanoarchitectonics for Two-Dimensional Films\"\n",
    "author = \"Ariga K\"\n",
    "entry = get_bibtex_entry(title, author)\n",
    "if entry:\n",
    "    print(entries_to_str([entry]))\n",
    "\n",
    "print(entry[\"doi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aisurveywriter import generate_paper_survey\n",
    "from aisurveywriter.utils import get_all_files_from_paths\n",
    "\n",
    "generate_paper_survey(\n",
    "    subject=\"Langmuir Monolayers and Langmuir-Blodgett Films\",\n",
    "    ref_paths=get_all_files_from_paths(\"D:/Dev/aisurveywriter/refexamples\"),\n",
    "    save_path=\"here.tex\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juliocesar/miniconda3/envs/llm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ReferenceExtractor) ==> started extracting references from pdf ArigaK2023_ChemOfMat.pdf\n"
     ]
    },
    {
     "ename": "ResponseError",
     "evalue": "model \"deepseek-r1:8b\" not found, try pulling it first (status code: 404)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m      8\u001b[0m prompt \u001b[38;5;241m=\u001b[39m fh\u001b[38;5;241m.\u001b[39mread_yaml(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../templates/prompt_config.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreference_extract_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      9\u001b[0m ref \u001b[38;5;241m=\u001b[39m ReferenceExtractor(llm\u001b[38;5;241m=\u001b[39mLLMHandler(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepseek-r1:8b\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mollama\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     10\u001b[0m                          ref_paths\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../refexamples/ArigaK2023_ChemOfMat.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m], prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m     11\u001b[0m                          raw_save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./raw.ref\u001b[39m\u001b[38;5;124m\"\u001b[39m, rawbib_save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./rawbib.bib\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m                          bib_save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./final.bib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m ref()\n",
      "File \u001b[0;32m~/Dev/aisurveywriter/src/aisurveywriter/tasks/reference_extract.py:40\u001b[0m, in \u001b[0;36mReferenceExtractor.__call__\u001b[0;34m(self, raw_save_path, rawbib_save_path, bib_save_path)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bib_save_path:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbib_save_path \u001b[38;5;241m=\u001b[39m bib_save_path\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_entry()\n",
      "File \u001b[0;32m~/Dev/aisurveywriter/src/aisurveywriter/tasks/reference_extract.py:27\u001b[0m, in \u001b[0;36mReferenceExtractor.pipeline_entry\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpipeline_entry\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 27\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_references(save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_save_path)\n\u001b[1;32m     28\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefs_to_bib(refs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawbib_save_path)\n\u001b[1;32m     29\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremove_duplicates(refs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbib_save_path)\n",
      "File \u001b[0;32m~/Dev/aisurveywriter/src/aisurveywriter/tasks/reference_extract.py:59\u001b[0m, in \u001b[0;36mReferenceExtractor.extract_references\u001b[0;34m(self, ref_paths, save_path)\u001b[0m\n\u001b[1;32m     54\u001b[0m named_log(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==> started extracting references from pdf \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# response = self.llm.invoke({\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m#     \"pdfcontent\": pdf,\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# })\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# elapsed = int(time() - start)\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m elapsed, response \u001b[38;5;241m=\u001b[39m time_func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39minvoke, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpdfcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: pdf})\n\u001b[1;32m     60\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(elapsed)\n\u001b[1;32m     62\u001b[0m references \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/Dev/aisurveywriter/src/aisurveywriter/utils/helpers.py:17\u001b[0m, in \u001b[0;36mtime_func\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtime_func\u001b[39m(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     16\u001b[0m     start \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m---> 17\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     18\u001b[0m     elapsed \u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m-\u001b[39m start\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(elapsed), ret\n",
      "File \u001b[0;32m~/Dev/aisurveywriter/src/aisurveywriter/core/llm_handler.py:68\u001b[0m, in \u001b[0;36mLLMHandler.invoke\u001b[0;34m(self, input_variables)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chain \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo call LLMHandler.invoke, the chain has to be initialized\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chain\u001b[38;5;241m.\u001b[39minvoke(input_variables)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_core/runnables/base.py:3016\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3014\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3015\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3016\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[1;32m   3017\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3018\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:284\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    280\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    281\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    283\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 284\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[1;32m    285\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[1;32m    286\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    287\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    288\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    289\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    290\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    291\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    292\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    293\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    294\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:860\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    854\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    859\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:690\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 690\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[1;32m    691\u001b[0m                 m,\n\u001b[1;32m    692\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    693\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    694\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    695\u001b[0m             )\n\u001b[1;32m    696\u001b[0m         )\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:925\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    924\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 925\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[1;32m    926\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    927\u001b[0m         )\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    929\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_ollama/chat_models.py:701\u001b[0m, in \u001b[0;36mChatOllama._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate\u001b[39m(\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    696\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    700\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[0;32m--> 701\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chat_stream_with_aggregation(\n\u001b[1;32m    702\u001b[0m         messages, stop, run_manager, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    703\u001b[0m     )\n\u001b[1;32m    704\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m final_chunk\u001b[38;5;241m.\u001b[39mgeneration_info\n\u001b[1;32m    705\u001b[0m     chat_generation \u001b[38;5;241m=\u001b[39m ChatGeneration(\n\u001b[1;32m    706\u001b[0m         message\u001b[38;5;241m=\u001b[39mAIMessage(\n\u001b[1;32m    707\u001b[0m             content\u001b[38;5;241m=\u001b[39mfinal_chunk\u001b[38;5;241m.\u001b[39mtext,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    711\u001b[0m         generation_info\u001b[38;5;241m=\u001b[39mgeneration_info,\n\u001b[1;32m    712\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_ollama/chat_models.py:602\u001b[0m, in \u001b[0;36mChatOllama._chat_stream_with_aggregation\u001b[0;34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chat_stream_with_aggregation\u001b[39m(\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    595\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    600\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatGenerationChunk:\n\u001b[1;32m    601\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stream_resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_stream(messages, stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    603\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stream_resp, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    604\u001b[0m             chunk \u001b[38;5;241m=\u001b[39m ChatGenerationChunk(\n\u001b[1;32m    605\u001b[0m                 message\u001b[38;5;241m=\u001b[39mAIMessageChunk(\n\u001b[1;32m    606\u001b[0m                     content\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    619\u001b[0m                 ),\n\u001b[1;32m    620\u001b[0m             )\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.12/site-packages/langchain_ollama/chat_models.py:589\u001b[0m, in \u001b[0;36mChatOllama._create_chat_stream\u001b[0;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m chat_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chat_params(messages, stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chat_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 589\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mchat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mchat_params)\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mchat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mchat_params)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.12/site-packages/ollama/_client.py:168\u001b[0m, in \u001b[0;36mClient._request.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    167\u001b[0m   e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m--> 168\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext, e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_lines():\n\u001b[1;32m    171\u001b[0m   part \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(line)\n",
      "\u001b[0;31mResponseError\u001b[0m: model \"deepseek-r1:8b\" not found, try pulling it first (status code: 404)"
     ]
    }
   ],
   "source": [
    "from aisurveywriter.tasks import ReferenceExtractor\n",
    "from aisurveywriter.core.llm_handler import LLMHandler\n",
    "import aisurveywriter.core.file_handler as fh\n",
    "\n",
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"]=\"\"\n",
    "\n",
    "prompt = fh.read_yaml(\"../templates/prompt_config.yaml\")[\"reference_extract_prompt\"]\n",
    "ref = ReferenceExtractor(llm=LLMHandler(model=\"deepseek-r1:7b\", model_type=\"ollama\"),\n",
    "                         ref_paths=[\"../refexamples/ArigaK2023_ChemOfMat.pdf\"], prompt=prompt,\n",
    "                         raw_save_path=\"./raw.ref\", rawbib_save_path=\"./rawbib.bib\",\n",
    "                         bib_save_path=\"./final.bib\")\n",
    "ref()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_abstract_from_doi(doi):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "        \"Accept\": \"application/vnd.citationstyles.csl+json\",\n",
    "    }\n",
    "    \n",
    "    # Step 1: Use CrossRef API\n",
    "    try:\n",
    "        crossref_url = f\"https://api.crossref.org/works?filter=has-abstract:true/{doi}\"\n",
    "        response = requests.get(crossref_url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            print(\"yes\")\n",
    "            data = response.json()\n",
    "            abstract = data[\"message\"].get(\"abstract\")\n",
    "            if abstract:\n",
    "                return abstract\n",
    "    except Exception as e:\n",
    "        print(f\"CrossRef failed: {e}\")\n",
    "\n",
    "    # Step 2: Access DOI redirection URL\n",
    "    try:\n",
    "        doi_url = f\"https://doi.org/{doi}\"\n",
    "        response = requests.get(doi_url, headers=headers, allow_redirects=True)\n",
    "        print(response)\n",
    "        if response.status_code == 200:\n",
    "            print(response.text)\n",
    "            print(\"abstract\" in response.text)\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"DOI redirection failed: {e}\")\n",
    "\n",
    "    # Step 3: If all else fails, return None\n",
    "    return None\n",
    "\n",
    "# Example usage\n",
    "doi = \"10.1021/acs.chemrev.1c00754\"\n",
    "abstract = get_abstract_from_doi(doi)\n",
    "if abstract:\n",
    "    print(\"Abstract found:\", abstract)\n",
    "else:\n",
    "    print(\"Abstract not found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
