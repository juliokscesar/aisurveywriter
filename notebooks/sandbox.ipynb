{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENVIRONMENT\n",
    "\n",
    "from aisurveywriter.core.llm_handler import LLMHandler\n",
    "import aisurveywriter.core.file_handler as fh\n",
    "from aisurveywriter.utils import get_all_files_from_paths\n",
    "from aisurveywriter.core.pipeline import PaperPipeline\n",
    "from aisurveywriter.core.paper import PaperData\n",
    "import aisurveywriter.tasks as tks\n",
    "\n",
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"]=fh.read_credentials(\"../credentials.yaml\")[\"google_key\"]\n",
    "\n",
    "# llm = LLMHandler(model=\"qwen2.5:14b\", model_type=\"ollama\", temperature=0.5)\n",
    "prompts = fh.read_yaml(\"../templates/prompt_config.yaml\")\n",
    "review = fh.read_yaml(\"../templates/review_config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize default prompt store\n",
    "\n",
    "from aisurveywriter.store.prompt_store import PromptStore, default_prompt_store\n",
    "import json\n",
    "\n",
    "old = default_prompt_store()\n",
    "\n",
    "with open(\"prompts-20250320.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(old.model_dump(), f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual RAG retrieval\n",
    "\n",
    "from aisurveywriter.core.agent_rags import AgentRAG, RAGType\n",
    "from aisurveywriter.core.text_embedding import EmbeddingsHandler\n",
    "\n",
    "embed = EmbeddingsHandler(\"Snowflake/snowflake-arctic-embed-l-v2.0\", \"huggingface\")\n",
    "rag = AgentRAG(embed, bib_faiss_path=\"../out/refextract-bibdb.faiss\", \n",
    "               figures_faiss_path=\"../out/figures-rag.faiss\", \n",
    "               content_faiss_path=\"../out/content-rag.faiss\",\n",
    "               request_cooldown_sec=6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = r\"meniscus effect\"\n",
    "rag.retrieve(RAGType.ImageData, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aisurveywriter.core.text_embedding import EmbeddingsHandler\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embed = EmbeddingsHandler(\"Snowflake/snowflake-arctic-embed-l-v2.0\", \"huggingface\")\n",
    "faiss = FAISS.load_local(\"../out/refextract-bibdb.faiss\", embeddings=embed.model, allow_dangerous_deserialization=True)\n",
    "faiss.similarity_search_with_score(\"This review presents a comprehensive overview of these techniques, crucial for producing high-quality LB films. Ultimately, a deeper understanding of Langmuir monolayer characterization empowers the development of advanced materials and devices across diverse fields, pushing the boundaries of nanoscience and nanotechnology\", k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image caption extraction test\n",
    "from aisurveywriter.core.pdf_processor import PDFProcessor, LayoutParserSettings\n",
    "from aisurveywriter.utils.helpers import get_all_files_from_paths\n",
    "\n",
    "lp_settings = LayoutParserSettings(config_path=\"lp://PubLayNet/mask_rcnn_X_101_32x8d_FPN_3x/config\", tesseract_executable=\"/home/juliocesar/bin/tesseract\", score_threshold=0.7)\n",
    "\n",
    "pdf = PDFProcessor([\"../refexamples/all21/OliveiraO2022_PastAndFuture.pdf\"], lp_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from aisurveywriter.core.agent_rags import AgentRAG, RAGType\n",
    "from aisurveywriter.core.text_embedding import EmbeddingsHandler\n",
    "from aisurveywriter.core.paper import PaperData\n",
    "from aisurveywriter.store.reference_store import ReferenceStore\n",
    "\n",
    "subject = \"Langmuir and **Langmuir-Blodgett Films**\"\n",
    "result_path = \"../results/137refs-sempatrycja/\"\n",
    "paper = PaperData.from_structure_json(subject, result_path+\"structure.json\")\n",
    "refstore = ReferenceStore.from_local(result_path+\"refstore.pkl\")\n",
    "\n",
    "embed = EmbeddingsHandler(\"Snowflake/snowflake-arctic-embed-l-v2.0\", \"huggingface\")\n",
    "rags = AgentRAG(\n",
    "    embed,\n",
    "    content_faiss_path=\"137/content-rag.faiss\"\n",
    ")\n",
    "#rags.create_rags(RAGType.GeneralText, refstore)\n",
    "\n",
    "query_fmt = \"Retrieve contextual, technical, and analytical information on the subject \" + subject + \" for a section titled \\\"{section_title}\\\", description:\\n{section_description}\"\n",
    " \n",
    "# keep track of N of blocks retrieved for each source\n",
    "source_retrievals = {\n",
    "    os.path.basename(p): 0 for p in refstore.paths\n",
    "}\n",
    "for i, section in enumerate(paper.sections):\n",
    "    results = rags.retrieve(RAGType.GeneralText, query_fmt.format(section_title=section.title, section_description=section.description), k=35)\n",
    "    print(f\"Retrieved {len(results)} chunks for section {i+1}: {section.title}\")\n",
    "    for result in results:\n",
    "        source = os.path.basename(result.source_pdf)\n",
    "        if source not in source_retrievals:\n",
    "            print(\"untracked source:\", source)\n",
    "            source_retrievals[source] = 0\n",
    "        source_retrievals[source] += 1\n",
    "\n",
    "source_retrievals = list(sorted(source_retrievals.items(), key=lambda x: x[1], reverse=True))\n",
    "print(source_retrievals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "files = [s[0] for s in source_retrievals]\n",
    "non_zero = [r for r in source_retrievals if r[1] > 0]\n",
    "print(\"# of references retrieved 0 times:\", len(source_retrievals) - len(non_zero))\n",
    "\n",
    "top_k = int(1 * len(source_retrievals))\n",
    "sources, amounts = zip(*(source_retrievals[:top_k]))\n",
    "source_ids = [files.index(s) for s in sources]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "ax.bar(source_ids, amounts)\n",
    "\n",
    "ax.set(ylabel=\"# retrieved chunks\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Top\", top_k, \"sources\")\n",
    "for source in sources:\n",
    "    print(source)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
