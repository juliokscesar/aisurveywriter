{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENVIRONMENT\n",
    "\n",
    "from aisurveywriter.core.llm_handler import LLMHandler\n",
    "import aisurveywriter.core.file_handler as fh\n",
    "from aisurveywriter.utils import get_all_files_from_paths\n",
    "from aisurveywriter.core.pipeline import PaperPipeline\n",
    "from aisurveywriter.core.paper import PaperData\n",
    "import aisurveywriter.tasks as tks\n",
    "\n",
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"]=fh.read_credentials(\"../credentials.yaml\")[\"google_key\"]\n",
    "\n",
    "# llm = LLMHandler(model=\"qwen2.5:14b\", model_type=\"ollama\", temperature=0.5)\n",
    "prompts = fh.read_yaml(\"../templates/prompt_config.yaml\")\n",
    "review = fh.read_yaml(\"../templates/review_config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize default prompt store\n",
    "\n",
    "from aisurveywriter.store.prompt_store import PromptStore, default_prompt_store\n",
    "import json\n",
    "\n",
    "old = default_prompt_store()\n",
    "\n",
    "with open(\"prompts-24022025.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(old.model_dump(), f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual RAG retrieval\n",
    "\n",
    "from aisurveywriter.core.agent_rags import AgentRAG, RAGType\n",
    "from aisurveywriter.core.text_embedding import EmbeddingsHandler\n",
    "\n",
    "embed = EmbeddingsHandler(\"Snowflake/snowflake-arctic-embed-l-v2.0\", \"huggingface\")\n",
    "rag = AgentRAG(embed, bib_faiss_path=\"../out/refextract-bibdb.faiss\", figures_faiss_path=\"../out/figures-rag.faiss\", content_faiss_path=\"../out/content-rag.faiss\",\n",
    "               request_cooldown_sec=6)\n",
    "\n",
    "query = r\"Schematic representation of a Langmuir trough that contains the Wilhelmy plate for measuring surface pressure using an electrobalance and a surface potential probe.   Also shown is the dipper employed for transferring Langmuir/Blodgett onto a solid substrate\"\n",
    "rag.retrieve(RAGType.ImageData, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image caption extraction test\n",
    "from aisurveywriter.core.pdf_processor import PDFProcessor\n",
    "from aisurveywriter.utils.helpers import get_all_files_from_paths\n",
    "\n",
    "# pdf = PDFProcessor([\"../refexamples/filter-artigos-rafael/103.pdf\"])\n",
    "pdf = PDFProcessor(get_all_files_from_paths(\"../refexamples/filter-artigos-rafael\", skip_ext=[\".txt\"]))\n",
    "# images = pdf.extract_images(\"test\")\n",
    "\n",
    "content = pdf.extract_content()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, c in enumerate(content):\n",
    "    c = c.lower()\n",
    "    if \"polarization dependence of the\" in c:\n",
    "        print(f\"found in {i}: {pdf.pdf_paths[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join([f\"{i}: {image.caption}\" for i,image in enumerate(images)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pdf.pdf_documents[0][9].page_content\n",
    "# text = text[text.find(\"9.\"):]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LayoutParser for pdf info extraction\n",
    "%pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install layoutparser pdf2image \"layoutparser[ocr]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import layoutparser as lp\n",
    "from layoutparser.models.detectron2 import catalog\n",
    "import copy\n",
    "import os\n",
    "import requests\n",
    "\n",
    "def load_model(\n",
    "        config_path: str = 'lp://<dataset_name>/<model_name>/config',\n",
    "        extra_config=None,\n",
    "):\n",
    "\n",
    "    config_path_split = config_path.split('/')\n",
    "    dataset_name = config_path_split[-3]\n",
    "    model_name = config_path_split[-2]\n",
    "\n",
    "    # get the URLs from the MODEL_CATALOG and the CONFIG_CATALOG \n",
    "    # (global variables .../layoutparser/models/detectron2/catalog.py)\n",
    "    model_url = catalog.MODEL_CATALOG[dataset_name][model_name]\n",
    "    config_url = catalog.CONFIG_CATALOG[dataset_name][model_name]\n",
    "\n",
    "    # override folder destination:\n",
    "    if 'model' not in os.listdir():\n",
    "        os.mkdir('model')\n",
    "\n",
    "    config_file_path, model_file_path = None, None\n",
    "\n",
    "    for url in [model_url, config_url]:\n",
    "        filename = url.split('/')[-1].split('?')[0]\n",
    "        save_to_path = f\"model/\" + filename\n",
    "        if 'config' in filename:\n",
    "            config_file_path = copy.deepcopy(save_to_path)\n",
    "        if 'model_final' in filename:\n",
    "            model_file_path = copy.deepcopy(save_to_path)\n",
    "\n",
    "        # skip if file exist in path\n",
    "        if filename in os.listdir(\"model\"):\n",
    "            continue\n",
    "        # Download file from URL\n",
    "        r = requests.get(url, stream=True, headers={'user-agent': 'Wget/1.16 (linux-gnu)'})\n",
    "\n",
    "        with open(save_to_path, \"wb\") as f:\n",
    "            for chunk in r.iter_content(chunk_size=4096):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "\n",
    "    # load the label map\n",
    "    label_map = catalog.LABEL_MAP_CATALOG[dataset_name]\n",
    "\n",
    "    return lp.models.Detectron2LayoutModel(\n",
    "        config_path=config_file_path,\n",
    "        model_path=model_file_path,\n",
    "        label_map=label_map,\n",
    "        extra_config=extra_config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import layoutparser as lp\n",
    "import pdf2image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "from PIL import Image\n",
    "\n",
    "pdf_image = pdf2image.convert_from_path(\"../refexamples/filter-artigos-rafael/18.pdf\")\n",
    "\n",
    "lp_model = load_model(\"lp://PubLayNet/mask_rcnn_X_101_32x8d_FPN_3x/config\", extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.75])\n",
    "lp_ocr = lp.TesseractAgent.with_tesseract_executable(\"/home/juliocesar/bin/tesseract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_image[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = lp_model.detect(pdf_image[0])\n",
    "lp.draw_box(pdf_image[0], layout, box_width=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp.draw_box(pdf_image[0], [b for b in layout if b.type == \"Title\"], box_width=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = []\n",
    "figure_count = 0\n",
    "output_dir = \"test\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for page_num, img in enumerate(pdf_image):\n",
    "    print(f\"Processing page {page_num + 1}/{len(pdf_image)}...\")\n",
    "        \n",
    "    # Convert PIL Image to OpenCV format\n",
    "    img_cv = np.array(img)\n",
    "    img_cv = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)\n",
    "    page_width, page_height = img.width, img.height\n",
    "    \n",
    "    layout = lp_model.detect(img_cv)\n",
    "    \n",
    "    # Sort blocks according to scientific paper reading order\n",
    "    # First divide the page into 4 quadrants and sort blocks by their position\n",
    "    def sort_blocks_by_scientific_layout(blocks):\n",
    "        # Define page midpoints\n",
    "        mid_x = page_width / 2\n",
    "        mid_y = page_height / 2\n",
    "        \n",
    "        # Group blocks by quadrant\n",
    "        top_left = []\n",
    "        top_right = []\n",
    "        bottom_left = []\n",
    "        bottom_right = []\n",
    "        \n",
    "        for block in blocks:\n",
    "            # Get block center\n",
    "            x1, y1, x2, y2 = block.coordinates\n",
    "            center_x = (x1 + x2) / 2\n",
    "            center_y = (y1 + y2) / 2\n",
    "            \n",
    "            # Assign to quadrant\n",
    "            if center_x < mid_x:\n",
    "                if center_y < mid_y:\n",
    "                    top_left.append(block)\n",
    "                else:\n",
    "                    bottom_left.append(block)\n",
    "            else:\n",
    "                if center_y < mid_y:\n",
    "                    top_right.append(block)\n",
    "                else:\n",
    "                    bottom_right.append(block)\n",
    "        \n",
    "        # Sort blocks within each quadrant by y-coordinate (top to bottom)\n",
    "        for quadrant in [top_left, top_right, bottom_left, bottom_right]:\n",
    "            quadrant.sort(key=lambda block: block.coordinates[1])\n",
    "        \n",
    "        # Combine quadrants in reading order: top-left, bottom-left, top-right, bottom-right\n",
    "        return top_left + bottom_left + top_right + bottom_right\n",
    "        \n",
    "    # Apply scientific layout sorting\n",
    "    layout = sort_blocks_by_scientific_layout(layout)\n",
    "\n",
    "    page_text = []\n",
    "    figure_blocks = []\n",
    "    text_blocks = []\n",
    "    \n",
    "    for block in layout:\n",
    "        # Extract coordinates\n",
    "        x1, y1, x2, y2 = block.coordinates\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "        \n",
    "        # Crop the region\n",
    "        region = img_cv[y1:y2, x1:x2]\n",
    "        \n",
    "        if block.type == \"Figure\":\n",
    "            figure_blocks.append(block)\n",
    "        elif block.type in [\"Text\", \"Title\", \"List\"]:\n",
    "            # Use LayoutParser's Tesseract agent for OCR\n",
    "            segment_image = (block\n",
    "                            .pad(left=5, right=5, top=5, bottom=5)\n",
    "                            .crop_image(img_cv))\n",
    "            \n",
    "            # Extract text using OCR\n",
    "            text = lp_ocr.detect(segment_image)\n",
    "            block.set(text=text, inplace=True)\n",
    "            text_blocks.append(block)\n",
    "            \n",
    "            # Add to the full text content (only from text blocks)\n",
    "            page_text.append(text)\n",
    "        \n",
    "    # Process figures and associate captions\n",
    "    for i, figure_block in enumerate(figure_blocks):\n",
    "        figure_count += 1\n",
    "        fig_x1, fig_y1, fig_x2, fig_y2 = [int(coord) for coord in figure_block.coordinates]\n",
    "        \n",
    "        # Extract the figure image\n",
    "        figure_img = img_cv[fig_y1:fig_y2, fig_x1:fig_x2]\n",
    "        figure_img_rgb = cv2.cvtColor(figure_img, cv2.COLOR_BGR2RGB)\n",
    "        figure_pil = Image.fromarray(figure_img_rgb)\n",
    "        \n",
    "        # Find the closest text block below the figure that could be a caption\n",
    "        caption = \"\"\n",
    "        min_distance = float('inf')\n",
    "        \n",
    "        for text_block in text_blocks:\n",
    "            text_y1 = text_block.coordinates[1]\n",
    "            text_x_center = (text_block.coordinates[0] + text_block.coordinates[2]) / 2\n",
    "            fig_x_center = (fig_x1 + fig_x2) / 2\n",
    "            \n",
    "            # Check if text block is below the figure and horizontally aligned\n",
    "            if (text_y1 > fig_y2 and \n",
    "                abs(text_x_center - fig_x_center) < (fig_x2 - fig_x1) / 2):\n",
    "                \n",
    "                distance = text_y1 - fig_y2\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    caption = text_block.text\n",
    "                    \n",
    "                    # Caption threshold - if it's too far, probably not a caption\n",
    "                    if min_distance > 100:\n",
    "                        caption = \"\"\n",
    "        \n",
    "        # Clean caption text (if found)\n",
    "        if caption:\n",
    "            # Look for patterns like \"Figure 1:\" or \"Fig. 1.\"\n",
    "            caption = caption.strip()\n",
    "            # Remove extra newlines\n",
    "            caption = re.sub(r'\\n+', ' ', caption)\n",
    "        \n",
    "        # Save figure with descriptive filename\n",
    "        figure_filename = f\"figure_{page_num+1}_{figure_count}.png\"\n",
    "        figure_path = os.path.join(output_dir, figure_filename)\n",
    "        figure_pil.save(figure_path)\n",
    "        \n",
    "        # Save caption to a corresponding text file\n",
    "        if caption:\n",
    "            caption_filename = f\"figure_{page_num+1}_{figure_count}_caption.txt\"\n",
    "            caption_path = os.path.join(output_dir, caption_filename)\n",
    "            with open(caption_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(caption)\n",
    "        \n",
    "        print(f\"Saved figure {figure_count} from page {page_num+1}\")\n",
    "\n",
    "    all_text.append(\"\\n\".join(page_text))\n",
    "    \n",
    "text_output_path = os.path.join(output_dir, \"extracted_text.txt\")\n",
    "with open(text_output_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"\\n\\n----- PAGE BREAK -----\\n\\n\".join(all_text))\n",
    "    \n",
    "print(f\"Extraction complete. Extracted {figure_count} figures and saved text to {text_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/AlexanderP/tesseract-appimage/releases/download/v5.5.0/tesseract-5.5.0-x86_64.AppImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aisurveywriter.core.new_pdf_processor import PDFProcessor\n",
    "\n",
    "proc = PDFProcessor([\"../refexamples/filter-artigos-rafael/37.pdf\"], lp_tesseract_exectuable=\"/home/juliocesar/bin/tesseract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(proc.documents[0].figures[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aisurveywriter.core.text_embedding import EmbeddingsHandler\n",
    "\n",
    "embed = EmbeddingsHandler(\"Snowflake/snowflake-arctic-embed-l-v2.0\", \"huggingface\")\n",
    "embed.model.embed_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aisurveywriter.store.reference_store import ReferenceStore\n",
    "\n",
    "refs = ReferenceStore.from_local(\"../out/refstore.pkl\")\n",
    "figs = [fig for fig in refs.all_figures() if fig.caption]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
